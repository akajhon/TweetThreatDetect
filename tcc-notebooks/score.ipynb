{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Proposta usando score ponderado"]},{"cell_type":"markdown","metadata":{},"source":["Observação: necessário executar baselines previamente e extrair GoogleNews via script start.sh"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T16:06:36.322806Z","iopub.status.busy":"2023-10-26T16:06:36.322448Z","iopub.status.idle":"2023-10-26T16:06:36.332735Z","shell.execute_reply":"2023-10-26T16:06:36.331749Z","shell.execute_reply.started":"2023-10-26T16:06:36.322778Z"},"trusted":true},"outputs":[],"source":["import spacy\n","import pandas as pd\n","import numpy as np\n","from sklearn.metrics import classification_report, accuracy_score\n","from gensim.models import KeyedVectors\n","from tqdm import tqdm\n","\n","model = KeyedVectors.load_word2vec_format(\n","    '../models/GoogleNews-vectors-negative300.bin', binary=True)\n","nlp = spacy.load('en_core_web_sm')\n","\n","with open('./input/glossary_fortinet.txt', 'r') as f:\n","    cybersecurity_words = [line.strip() for line in f.readlines()]\n","\n","\n","def accuracyScore(csv_path):\n","    \"\"\"Calcula e imprime a acurácia e o relatório de classificação comparando os rótulos verdadeiros e preditos carregados de um arquivo CSV.\"\"\"\n","    csv = pd.read_csv(csv_path)\n","    true_labels = csv['annotation']\n","    predicted_labels = csv['final_score']\n","    report = classification_report(true_labels, predicted_labels)\n","    accuracy = accuracy_score(true_labels, predicted_labels)\n","    print(f\"Acurácia: {accuracy*100:.2f}%\")\n","    print(report)\n","\n","\n","def normalize_value(x, min_value, max_value, new_min=0, new_max=1):\n","    \"\"\"Normaliza um valor x no intervalo [min_value, max_value] para um novo intervalo [new_min, new_max].\"\"\"\n","    if x < min_value or x > max_value:\n","        x = max(min(x, max_value), min_value)\n","    normalized_x = new_min + ((new_max - new_min) *\n","                              (x - min_value)) / (max_value - min_value)\n","    return normalized_x\n","\n","\n","def get_word_vectors(text):\n","    \"\"\"Retorna os vetores das palavras no texto que estão presentes no modelo.\"\"\"\n","    word_vectors = []\n","    for word in text.split():\n","        if word in model:\n","            word_vectors.append(model[word])\n","    return word_vectors\n","\n","\n","def text_to_vector(text):\n","    \"\"\"Converte o texto em um vetor médio dos vetores das palavras.\"\"\"\n","    word_vectors = get_word_vectors(text)\n","    if not word_vectors:\n","        return np.zeros(300)\n","    return np.mean(word_vectors, axis=0)\n","\n","\n","glossary_vectors = {\n","    term: text_to_vector(term)\n","    for term in cybersecurity_words\n","    if text_to_vector(term) is not None\n","}\n","\n","\n","def cosine_similarity(vector1, vector2):\n","    \"\"\"Calcula a similaridade de cosseno entre dois vetores.\"\"\"\n","    norm_vector1 = np.linalg.norm(vector1)\n","    norm_vector2 = np.linalg.norm(vector2)\n","\n","    if not norm_vector1 or not norm_vector2:\n","        return 0\n","\n","    dot_product = np.dot(vector1, vector2)\n","    similarity = dot_product / (norm_vector1 * norm_vector2)\n","    return similarity\n","\n","\n","def cybersecurity_context(text):\n","    \"\"\"Calcula o contexto de cibersegurança do texto com base na similaridade com termos do glossário.\"\"\"\n","    text_vector = text_to_vector(text)\n","    similarities = []\n","\n","    for glossary_vector in glossary_vectors.values():\n","        if text_vector is not None and glossary_vector is not None:\n","            similarity = cosine_similarity(text_vector, glossary_vector)\n","            similarities.append(similarity)\n","\n","    if similarities:\n","        average_similarity = np.mean(similarities)\n","        normalized_similarity = normalize_value(average_similarity, 0, 1)\n","        return min(max(normalized_similarity, 0), 1)\n","    else:\n","        return 0\n","\n","\n","def entity_in_text(text):\n","    \"\"\"Avalia o texto e retorna uma pontuação com base nas entidades nomeadas presentes e na presença de palavras-chave relevantes.\"\"\"\n","    doc = nlp(text)\n","    entity_scores = {\n","        'CARDINAL': 0.33,\n","        'DATE': 0.33,\n","        'ORG': 0.33,\n","    }\n","    freq_score = sum(entity_scores.get(ent.label_, 0) for ent in doc.ents)\n","    normalized_value = normalize_value(freq_score, 0, 1)\n","    return min(max(normalized_value, 0), 1)\n","\n","\n","def calculate_score(text, sentiment, org_entity, cybersecurity_context, score, sentiment_weight, org_entity_weight, cybersecurity_context_weight, score_weight, threshold):\n","    \"\"\"Calcula e retorna uma pontuação global normalizada, com base nas métricas fornecidas e seus respectivos pesos, para determinar se o texto está relacionado à cibersegurança.\"\"\"\n","    weighted_sentiment = sentiment_weight * sentiment\n","    weighted_org_entity = org_entity_weight * org_entity\n","    weighted_cybersecurity_context = cybersecurity_context_weight * cybersecurity_context\n","    weighted_score = score_weight * score\n","\n","    score = weighted_sentiment + weighted_org_entity + \\\n","        weighted_cybersecurity_context + weighted_score\n","    max_score = sentiment_weight + org_entity_weight + \\\n","        cybersecurity_context_weight + score_weight\n","    normalized_score = normalize_value(score, 0, max_score)\n","    if normalized_score >= threshold:\n","        return 1\n","    else:\n","        return 0\n","\n","\n","def extract_sentiment():\n","    \"\"\"Processa os textos em um arquivo CSV, avalia várias métricas (sentimento, \n","    pontuação de entidade e contexto de cibersegurança) e salva os resultados, \n","    juntamente com uma pontuação global calculada, em um novo arquivo CSV.\"\"\"\n","    csv = pd.read_csv(\"./input/baselines/resultados.csv\")\n","    list_score = []\n","    i = 0\n","    total_rows = csv.shape[0]\n","    for key, value in tqdm(csv.iterrows(), total=total_rows):\n","        text = value['text']\n","        sentiment = value['sentiment']\n","        entity_score = entity_in_text(text)\n","        context_score = cybersecurity_context(text)\n","        score = value['SVM_TFIDF']\n","        # SVM_TFIDF\n","        # SVM_W2V\n","        # KNN_TFIDF\n","        # KNN_W2V\n","        # NV_TFIDF\n","        # NV_W2V\n","        # RF_TFIDF\n","        # RF_W2V\n","\n","        sentiment_weight = 0.3\n","        org_entity_weight = 0.3\n","        cybersecurity_context_weight = 0.3\n","        score_weight = 0.1\n","        threshold = 0.9\n","\n","        res_score = calculate_score(text, sentiment, entity_score, context_score, score, sentiment_weight,\n","                                    org_entity_weight, cybersecurity_context_weight, score_weight, threshold)\n","        list_score.append(res_score)\n","\n","    csv['final_score'] = list_score\n","    csv.to_csv(\"./output/resultados_new.csv\", index=False)\n","\n","\n","extract_sentiment()\n","accuracyScore(\"./output/resultados_new.csv\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":6763,"sourceId":9801,"sourceType":"datasetVersion"},{"datasetId":3582513,"sourceId":6541630,"sourceType":"datasetVersion"},{"datasetId":3564055,"sourceId":6597787,"sourceType":"datasetVersion"},{"datasetId":3878436,"sourceId":6779609,"sourceType":"datasetVersion"}],"dockerImageVersionId":30558,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
