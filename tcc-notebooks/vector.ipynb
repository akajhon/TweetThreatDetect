{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Proposta usando única representação vetorial"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-14T02:34:56.768225Z","iopub.status.busy":"2023-11-14T02:34:56.767841Z","iopub.status.idle":"2023-11-14T02:43:13.356945Z","shell.execute_reply":"2023-11-14T02:43:13.355469Z","shell.execute_reply.started":"2023-11-14T02:34:56.768182Z"},"trusted":true},"outputs":[],"source":["import spacy\n","import pytz\n","import pandas as pd\n","import numpy as np\n","import requests\n","import os\n","import pickle\n","from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.feature_selection import RFECV\n","from sklearn.naive_bayes import MultinomialNB, GaussianNB\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from gensim.models import KeyedVectors\n","from sklearn.svm import SVC\n","from collections import defaultdict\n","from tqdm import tqdm\n","from datetime import datetime\n","\n","model = KeyedVectors.load_word2vec_format(\n","    '../models/GoogleNews-vectors-negative300.bin', binary=True)\n","nlp = spacy.load('en_core_web_sm')\n","\n","with open('./input/glossary_fortinet.txt', 'r') as f:\n","    cybersecurity_words = [line.strip() for line in f.readlines()]\n","\n","\n","def train_and_evaluate_random_forest(X, y):\n","    \"\"\"Treina um modelo Random Forest usando os conjuntos de treinamento fornecidos e avalia sua performance nos conjuntos de teste.\"\"\"\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y, test_size=0.2, random_state=42)\n","\n","    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","    rf_model.fit(X_train, y_train)\n","\n","    with open('random_forest_model.pkl', 'wb') as model_file:\n","        pickle.dump(rf_model, model_file)\n","\n","    y_pred = rf_model.predict(X_test)\n","    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","\n","\n","def evaluate_svm(text):\n","    vector = text_to_vector(text)\n","    with open('./input/mysvmclassifier/SVM.pkl', 'rb') as model_file:\n","        loaded_svm_model = pickle.load(model_file)\n","\n","    pred_range = loaded_svm_model.predict_proba([vector])\n","    prob_second_class = pred_range[0][1]\n","    return prob_second_class\n","\n","\n","def accuracyScore(csv_path):\n","    \"\"\"Calcula e imprime a acurácia e o relatório de classificação comparando os rótulos verdadeiros e preditos carregados de um arquivo CSV.\"\"\"\n","    csv = pd.read_csv(csv_path)\n","    true_labels = csv['annotation']\n","    predicted_labels = csv['context']\n","    report = classification_report(true_labels, predicted_labels)\n","    accuracy = accuracy_score(true_labels, predicted_labels)\n","    print(f\"Acurácia: {accuracy*100:.2f}%\")\n","    print(report)\n","\n","\n","def normalize_value(x, min_value, max_value, new_min=0, new_max=1):\n","    \"\"\"Normaliza um valor x no intervalo [min_value, max_value] para um novo intervalo [new_min, new_max].\"\"\"\n","    if x < min_value or x > max_value:\n","        x = max(min(x, max_value), min_value)\n","    normalized_x = new_min + ((new_max - new_min) *\n","                              (x - min_value)) / (max_value - min_value)\n","    return normalized_x\n","\n","\n","def get_word_vectors(text):\n","    \"\"\"Retorna os vetores das palavras no texto que estão presentes no modelo.\"\"\"\n","    word_vectors = []\n","    for word in text.split():\n","        if word in model:\n","            word_vectors.append(model[word])\n","    return word_vectors\n","\n","\n","def text_to_vector(text):\n","    \"\"\"Converte o texto em um vetor médio dos vetores das palavras.\"\"\"\n","    word_vectors = get_word_vectors(text)\n","    if not word_vectors:\n","        return np.zeros(300)\n","    return np.mean(word_vectors, axis=0)\n","\n","\n","glossary_vectors = {\n","    term: text_to_vector(term).squeeze()\n","    for term in cybersecurity_words\n","}\n","\n","\n","def cosine_similarity(vector1, vector2):\n","    \"\"\"Calcula a similaridade de cosseno entre dois vetores.\"\"\"\n","    norm_vector1 = np.linalg.norm(vector1)\n","    norm_vector2 = np.linalg.norm(vector2)\n","\n","    if not norm_vector1 or not norm_vector2:\n","        return 0\n","\n","    dot_product = np.dot(vector1, vector2)\n","    similarity = dot_product / (norm_vector1 * norm_vector2)\n","    return similarity\n","\n","\n","def cybersecurity_context(text):\n","    \"\"\"Calcula o contexto de cibersegurança do texto com base na similaridade com termos do glossário.\"\"\"\n","    text_vector = text_to_vector(text)\n","    similarities = []\n","\n","    for glossary_vector in glossary_vectors.values():\n","        if text_vector is not None and glossary_vector is not None:\n","            similarity = cosine_similarity(text_vector, glossary_vector)\n","            similarities.append(similarity)\n","\n","    if similarities:\n","        average_similarity = np.mean(similarities)\n","        normalized_similarity = normalize_value(average_similarity, 0, 1)\n","        return min(max(normalized_similarity, 0), 1)\n","    else:\n","        return 0\n","\n","\n","def entity_in_text(text):\n","    \"\"\"Avalia o texto e retorna uma pontuação com base nas entidades nomeadas presentes e na presença de palavras-chave relevantes.\"\"\"\n","    doc = nlp(text)\n","    entity_scores = {\n","        \"CARDINAL\": 0.3208,\n","        \"DATE\": 0.3807,\n","        \"EVENT\": 0.0002,\n","        \"FAC\": 0.0003,\n","        \"GPE\": 0.0392,\n","        \"LANGUAGE\": 0.0002,\n","        \"LAW\": 0.0004,\n","        \"LOC\": 0.0030,\n","        \"MONEY\": 0.0014,\n","        \"NORP\": 0.0254,\n","        \"ORDINAL\": 0.0097,\n","        \"ORG\": 0.1288,\n","        \"PERCENT\": 0.0003,\n","        \"PERSON\": 0.0630,\n","        \"PRODUCT\": 0.0052,\n","        \"QUANTITY\": 0.0133,\n","        \"TIME\": 0.0079,\n","        \"WORK_OF_ART\": 0.0003,\n","    }\n","    freq_score = sum(entity_scores.get(ent.label_, 0) for ent in doc.ents)\n","    normalized_value = normalize_value(freq_score, 0, 1)\n","    return min(max(normalized_value, 0), 1)\n","\n","\n","def extract_sentiment():\n","    \"\"\"Processa os textos em um arquivo CSV, avalia várias métricas (sentimento, \n","    pontuação de entidade e contexto de cibersegurança) e salva os resultados, \n","    juntamente com uma pontuação global calculada, em um novo arquivo CSV.\"\"\"\n","    csv = pd.read_csv(\n","        \"./input/validation_sentiment.csv\")\n","    y_train = csv['annotation'].values\n","    all_vectors = []\n","    for key, value in tqdm(csv.iterrows(), total=csv.shape[0]):\n","        text = value['text']\n","        sentiment = value['sentiment']\n","        entity_score = entity_in_text(text)\n","        context_score = cybersecurity_context(text)\n","        svm_prediction = evaluate_svm(text)\n","        vector = text_to_vector(text)\n","        full_vector = np.concatenate(\n","            (vector, sentiment, entity_score, context_score, svm_prediction), axis=None)\n","        all_vectors.append(full_vector)\n","    train_and_evaluate_random_forest(\n","        np.array(all_vectors, dtype=object), y_train)\n","\n","\n","extract_sentiment()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":6763,"sourceId":9801,"sourceType":"datasetVersion"},{"datasetId":3582513,"sourceId":6541630,"sourceType":"datasetVersion"},{"datasetId":3564055,"sourceId":6597787,"sourceType":"datasetVersion"}],"dockerImageVersionId":30558,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
